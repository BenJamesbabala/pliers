{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Go through movie->features pipeline manually'''\n",
    "# First load the stimulus\n",
    "from featurex.tests.utils import get_test_data_path\n",
    "from os.path import join\n",
    "from featurex.stimuli.video import VideoStim\n",
    "from featurex.converters.video import VideoToAudioConverter, FrameSamplingConverter\n",
    "from featurex.converters.image import TesseractConverter\n",
    "from featurex.converters.api import WitTranscriptionConverter\n",
    "from featurex.extractors import ExtractorResult\n",
    "from featurex.extractors.image import VibranceExtractor\n",
    "from featurex.extractors.text import LengthExtractor\n",
    "from featurex.graph import Graph, Node\n",
    "\n",
    "filename = join(get_test_data_path(), 'video', 'obama_speech.mp4')\n",
    "video = VideoStim(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Writing audio in /Users/quinnmac/Library/Python/2.7/lib/python/site-packages/featurex-0.0.1-py2.7.egg/featurex/tests/data/video/obama_speech.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:00<00:00, 1478.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the audio\n",
    "conv = VideoToAudioConverter()\n",
    "audio = conv.convert(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subsample the video\n",
    "conv = FrameSamplingConverter(every=15)\n",
    "derived = conv.convert(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract text from the video\n",
    "conv = TesseractConverter()\n",
    "visual_texts = []\n",
    "for frame in derived:\n",
    "    visual_texts.append(conv.convert(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract text from the audio\n",
    "conv = WitTranscriptionConverter()\n",
    "audio_text = conv.convert(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract a low-level image feature from each frame\n",
    "ext = VibranceExtractor()\n",
    "visual_features = []\n",
    "for frame in derived:\n",
    "    visual_features.append(ext.extract(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract word length from both audio and visual text\n",
    "ext = LengthExtractor()\n",
    "visual_length = [ext.extract(t) for t in visual_texts]\n",
    "audio_length = [ext.extract(t) for t in audio_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        onset  duration    vibrance\n",
      "  stim                             \n",
      "0 0       NaN       NaN  418.851528\n",
      "  15      NaN       NaN  441.618626\n",
      "  30      NaN       NaN  506.321013\n",
      "  45      NaN       NaN  575.903070\n",
      "  60      NaN       NaN  586.500651\n",
      "  75      NaN       NaN  590.007483\n",
      "  90      NaN       NaN  589.524823\n",
      "                                                      onset  duration  \\\n",
      "  stim                                                                  \n",
      "0                                                       NaN       NaN   \n",
      "                                                        NaN       NaN   \n",
      "                                                        NaN       NaN   \n",
      "  mslnsu-r onu‘ﬁ. SAVEIENV nu IRAN                      NaN       NaN   \n",
      "  1'\"\\nPIESIIIE Y' I' I ‘ s\\nt 1'. I)“; 555'} HEM...    NaN       NaN   \n",
      "                                                        NaN       NaN   \n",
      "  , 7 V\\nPnEslnEMJ'W min: an Inn:\\nA ‘                  NaN       NaN   \n",
      "\n",
      "                                                      text_length  \n",
      "  stim                                                             \n",
      "0                                                               0  \n",
      "                                                                0  \n",
      "                                                                0  \n",
      "  mslnsu-r onu‘ﬁ. SAVEIENV nu IRAN                             36  \n",
      "  1'\"\\nPIESIIIE Y' I' I ‘ s\\nt 1'. I)“; 555'} HEM...           56  \n",
      "                                                                0  \n",
      "  , 7 V\\nPnEslnEMJ'W min: an Inn:\\nA ‘                         36  \n",
      "                onset  duration  text_length\n",
      "  stim                                      \n",
      "0 today           NaN       NaN            5\n",
      "  after           NaN       NaN            5\n",
      "  two             NaN       NaN            3\n",
      "  years           NaN       NaN            5\n",
      "  of              NaN       NaN            2\n",
      "  negotiations    NaN       NaN           12\n"
     ]
    }
   ],
   "source": [
    "# Merge and display results\n",
    "print ExtractorResult.merge_stims(visual_features)\n",
    "print ExtractorResult.merge_stims(visual_length)\n",
    "print ExtractorResult.merge_stims(audio_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Writing audio in /Users/quinnmac/Library/Python/2.7/lib/python/site-packages/featurex-0.0.1-py2.7.egg/featurex/tests/data/video/obama_speech.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:00<00:00, 1874.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'stim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-13be29a3d470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/quinnmac/Library/Python/2.7/lib/python/site-packages/featurex-0.0.1-py2.7.egg/featurex/graph.pyc\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, stims)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mstims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/quinnmac/Library/Python/2.7/lib/python/site-packages/featurex-0.0.1-py2.7.egg/featurex/extractors/__init__.pyc\u001b[0m in \u001b[0;36mmerge_results\u001b[0;34m(results, extractor_names, stim_names)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mstims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# First concatenate all features separately for each Stim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'stim'"
     ]
    }
   ],
   "source": [
    "# Graph way of doing the same pipeline\n",
    "visual_nodes = [(FrameSamplingConverter(every=15), 'framesampling', \n",
    "             [(TesseractConverter(), 'visual_text', \n",
    "                [(LengthExtractor(), 'text_length')]), \n",
    "              (VibranceExtractor(), 'visual_vibrance')])]\n",
    "audio_nodes = [(VideoToAudioConverter(), 'audio', \n",
    "            [(WitTranscriptionConverter(), 'audio_text', \n",
    "              [(LengthExtractor(), 'text_length')])])]\n",
    "\n",
    "graph = Graph()\n",
    "graph.add_children(visual_nodes)\n",
    "graph.add_children(audio_nodes)\n",
    "graph.extract(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
